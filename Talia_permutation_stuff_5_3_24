#in this file I hope to do a simple permutation test on some made up data just 
# to hopefully work through the mechanics of it. 

#louad the libreary "data.table" so that I will be able to create a data table
library("data.table") 

# create a data table using some noncese data.
# this data frame has to collomes and two rows representing two groups and 
# two results, repsectivly. We can think of the two groups as treatment and 
# control and the two results as success and failure.
dataTest= data.table(c(57, 33), c(101, 90))

# add row and colomn names to dataTest. Even though it isn't based on 
# anthing I am naming the columns treatment and control and the 
# rows sucess and failure to that it will hopfully make it easer to think 
# through what I am doing. 
colnames(dataTest) = c('treatment', 'control')
rownames(dataTest) <- c('succsess', 'failure')

#call dataTest to make sure everything worked. 
dataTest
# treatment control
# 1:        57     101
# 2:        33      90

#okay, so the "success" and "failure " labels didn't seem to happen.
# no idea why and not worth it to deal with now, but consider the 
# first row success and the second row failure. 

#Now for the actual permutation test. 

#Notice that Treatment~Binom(57+33=90, pi1)
# and Control~Binom(101+90=191, pi2)

#Ho: pi1=pi2, we will estimate pi1=pi2=success/total
( 57 + 101)/(57 + 101+33+90) # 0.5622776 aprox. 0.56
#there must be a more automated way to do that, but whatever for now

#Ha: pi1 != pi2

#Permuting the data should esentaly mean generating a random number of success
# under the null hypothoses 
# we can use rbinom to generate random responces 
# will do 30 permutations 
treatmentPermData <- rbinom(30, 90, 0.56)
controlPermData <- rbinom(30, 191, 0.56)

#Now we need to use each of the permutations to create an estimate of 
# the proportion of sucesses for the treatment and control
#I'm not sure if this is how I should do it, but I am just going to
# devide the number of successes by the total number of subjects
# for each group, and have that be my estimated proportion. 
treatmentPermProps<-treatmentPermData / 90
controlPermProps<-controlPermData / 191

# now to get our sample of test statistics (or our null distrabultion)
# we will want to take the differince of the estimated proportion of 
# sucesses for the treatment group minus the estimated proportion of 
# sucesses for the control group for each of our permutations 
TestStatistics <- treatmentPermProps-controlPermProps

#call test TestStatistics just to make sure everthing worked out. 
#It seems resonable. 
TestStatistics

#Now I will find the test statistic for our actual data. 
(57/90) - (101/90) #-0.4888889 aprox. -0.49

#make a variable named MyTestStat equal to our test statistic for me to use later
MyTestStat <- -0.49

#Now I need to find a way to test if that is unusaul for the null distribultion 
# I have created. (just looking, we can see that it is, but still)

#I'm note sure if this is what I'm supposed to do but I'm going to estimate
# the mean and standered deviation just by using the mean and sd of the 
# sample. (I think it turns out I didn't actully need these)
mean(TestStatistics) #-0.01166958
sd(TestStatistics) #0.06674174

#to find the p-vaue we need to find what proportion of the test statistics in 
# the null distribution we created that are as or more extream then the 
# true test statistic. This, I think, is really why permutation tests are so 
# powerful. We don't need to have any knolige or guesses about the 
# shape of teh null distribution because we have the litteral thing (or
# enough of it)

#So, we are litterly just couning how many test statistics are as or
# more extream then or equal to our test statistic, and dividing that 
# by the total number of test statistics in our null distribution sample, 
#and that is our p-value.

#We know that the distribution should be centered on zero. 
# in this case our test statistic is negitive, but we want to do a two 
# taild test statistic. I think in this case the simpliist thing to do 
# is just to count anything that is less then or equal to -0.49 or equal to
# or greater then 0.49. (with -0.49 being or test statistic)

NegTestStat = -1*MyTestStat
NegTestStat


# declare a variable count and set it equal to zero that I will use to count
# how many test statistics are equal to or greater then 
count <- 0

#this is just a for loop that adds one to the varible count any time
# somthing is as or more extream then the test statistic as described above. 
# right now all the numbers pasikly are hardcoded in
for (i in TestStatistics) {
  
  if(i < -.49 || i>.49 || i==-.49 || i==.49) { 
    count = count +1 
    print(i) #printing the ones that are less then or grater just to see it working
  }
}

#call coout to find out how many where at least as extream
#right now when we call count we actully get zero, but -.49 is 
#way more extream then any of the test statistics in the null
#this would probleblly not happen if we where doing like ten thousand
# permutations insted of 30. 
count

# now we should really have a function that puts all of that together so 
# that we can just put in data and get a p-value. But that is going to 
# be a lot of coding and making small functiosn and calling them in bit
# functions and stuff. 


#What we really want to do is do this  a ton more times, get a ton of p-values and anilize the distribution of 
# p-values. probebly we want some nice code that does that aoutomaticly. 
# for now I am just going to make up some more pretend data to figure out a
# bit of the coding. 

#make fake data (a fake set of 10 p-values) just by using a runif to get 
# ten random values betwen 0 and 1 (so this would be pluasable data if
# every p-value was equaly likely)
FakePVals<-runif(10, 0, 1)

var(FakePVals) #0.0975965

#so then we would want to look at this variance and if it's higher then .01(which 
# it is but who cares this isn't reall data) we would want to start from the 
# begining again with a greater number of permutatiosn and see where that gets us.
